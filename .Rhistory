view(filtered_data)
filtered_data_2 <- filtered_data %>%
filter(AttentionCheck1 == "")
myPath=(dirname(rstudioapi::getActiveDocumentContext()$path))
data=read.csv(paste(myPath,"StateKey.csv",sep="/"))
state_key <- read.csv("StateKey.csv")
head(state_key)
library(dplyr)
merged_data <- left_join(filtered_data_2, state_key, by = "State")
view(merged_data)
state_data <- merged_data[, c("State", "StateName")]
view(state_data)
state_percent <- state_data %>%
group_by(StateName) %>%
summarize(count = n()) %>%
mutate(percent = count / sum(count) * 100)
view(state_percent)
ggplot(state_percent, aes(x = StateName, y = percent)) +
geom_bar(stat = "identity", fill = "blue") +
xlab("State") +
ylab("Percentage of Respondents") +
ggtitle("Percentage Breakdown of Respondents by State")+
theme(axis.text.x = element_text(angle = 90))
states_stacked=ggplot(data=state_percent,aes(x=StateName, fill=percent))+
geom_bar(position="fill")
states_stacked
facetgraph_columns <- merged_data %>%
select(Extraversion, Conscientiousness, Openness, Agreeableness, EmotionalStability, Politics)
view(facetgraph_columns)
bigfive_means <- facetgraph_columns %>%
group_by(Politics) %>%
summarize(
Extraversion_mean = mean(Extraversion, na.rm = TRUE),
Conscientiousness_mean = mean(Conscientiousness, na.rm = TRUE),
Openness_mean = mean(Openness, na.rm = TRUE),
Agreeableeness_mean = mean(Agreeableness, na.rm = TRUE),
EmotionalStability_mean = mean(EmotionalStability, na.rm = TRUE))
big_five_traits <- c("Extraversion", "Conscientiousness", "Openness", "Agreeableness", "EmotionalStability")
view(big_five_traits)
library(tidyverse)
bigfive_means_long <- bigfive_means %>%
pivot_longer(cols = c(Extraversion_mean, Conscientiousness_mean, Openness_mean, Agreeableeness_mean, EmotionalStability_mean),
names_to = "Trait",
values_to = "Score")
view(bigfive_means_long)
ggplot(bigfive_means_long, aes(x = Politics, y = Score)) +
geom_point() +
ggtitle("The Average Big Five Trait Scores with Political Orientation")+
facet_wrap(~Trait, scales = "free_y")
ggplot(bigfive_means_long, aes(x = Politics, y = Score)) +
geom_point() +
ggtitle("The Average Big Five Trait Scores with Political Orientation")+
facet_wrap(~Trait, scales = "free_y") +
stat_smooth(method = "lm", se = FALSE)
freestyle_columns <- merged_data[, c("Age", "Gender")]
view(freestyle_columns)
library(dplyr)
library(ggplot2)
freestyle_columns <- freestyle_columns %>%
mutate(gender_label = ifelse(Gender == 1, "Male", "Female"))
view(freestyle_columns)
age_gender_counts <- freestyle_columns %>%
group_by(Age, gender_label) %>%
summarize(count = n()) %>%
age_gender_counts <- freestyle_columns %>%
group_by(Age, gender_label) %>%
summarize(count = n())
view(age_gender_counts)
ggplot(age_gender_counts, aes(x = Age, y = count, fill = gender_label)) +
geom_area(alpha = 0.5) +
ggtitle("Breakdown of Respondents Age based on Gender")+
scale_fill_manual(values = c("Male" = "blue", "Female" = "pink")) +
labs(x = "Age", y = "Count", fill = "Gender")
# load data
myPath=dirname(rstudioapi::getActiveDocumentContext()$path)
data=read.csv(paste(myPath,"OS295_Survey_Raw.csv",sep="/"))
# load packages
library(tidyverse)
library(ggplot2)
# filter mturk data so any attention check values that do NOT align with instructions are excluded
# also filter out users that provided faulty or empty written responses
bad_resp = c("R_32L0vgYQzLcQiPd","R_2fxQxBrNzA3PF7X","R_1LZ0vKDaZ7mkav6","R_20SCqZPnko7PRL0","R_31Yr5lEvkkVTuSh","R_3qx2CTtdfsETT7l","R_x4SknfGlhCVNwgp")
new_data = data %>%
filter(
(AttentionCheck1 == "") &
(AttentionCheck2 == 3) &
(!ResponseId %in% bad_resp)
)
head(new_data)
# create bar plot that compares starbucks vs dunkin donuts and preference for popular restaurants
sb_dd_popular = ggplot(
data=new_data,
aes(
x=factor(Coffee), # factor function lets me rename values later
y=RestaurantPrefs_popular, # heights of bars rep
fill=factor(Coffee) # setting it as fill lets me color the bars
)
) +
geom_bar(stat="summary", fun=mean) + # measures means, not counts
labs(
title="Preference for Starbucks and Dunkin vs Preference for Popularity",
x="Coffee Place",
y="Average Preference for Popularity") +
scale_fill_manual(
values=c("#00704A","#f5821f","gray")) + # applies colors
scale_x_discrete(
labels=c("1" = "Starbucks", "2" = "Dunkin Donuts","3" = "Other")) + # changes x variable labels (instead of just integers)
theme(legend.position = "none") # hide legend
sb_dd_popular
# create bar plot that compares starbucks vs dunkin donuts and preference for popular restaurants
sb_dd_popular = ggplot(
data=new_data,
aes(
x=factor(Coffee), # factor function lets me rename values later
y=RestaurantPrefs_popular, # heights of bars rep
fill=factor(Coffee) # setting it as fill lets me color the bars
)
) +
geom_bar(stat="summary", fun=mean) + # measures means, not counts
labs(
title="Preference for Starbucks and Dunkin vs Preference for Popularity",
x="Coffee Place",
y="Average Preference for Popularity") +
scale_fill_manual(
values=c("#00704A","#f5821f","gray")) + # applies colors
scale_x_discrete(
labels=c("1" = "Starbucks", "2" = "Dunkin Donuts","3" = "Other")) + # changes x variable labels (instead of just integers)
theme(legend.position = "none") # hide legend
sb_dd_popular
# create new column that computes average extraversion
new_data$avg_extraversion = ((new_data$Extraversion + (8-new_data$ExtraversionR)) / 2)
# create new dataframe in long format - restaurant characteristics are the "names" and their preference ratings are the "values"
restaurant_long=new_data %>%
pivot_longer(
cols = RestaurantPrefs_quiet:RestaurantPrefs_familiar) %>%
filter(!is.na(value))
# create list of names - will use later to label graphs
restaurant_names = c(
`RestaurantPrefs_exciting` = "Exciting",
`RestaurantPrefs_familiar` = "Familiar",
`RestaurantPrefs_inexpensive` = "Inexpensive",
`RestaurantPrefs_popular` = "Popular",
`RestaurantPrefs_quiet` = "Quiet",
`RestaurantPrefs_unusual` = "Unusual"
)
# create correlation plot
extravert_facet = ggplot(
data=restaurant_long,
aes(x=avg_extraversion,y=value)
) +
geom_point(color="blue",alpha=0.3) +
facet_wrap(.~name, labeller = as_labeller(restaurant_names)) + # label graphs
labs(
title="Extraversion vs Preference for Restaurant Characteristics",
x="Average Extraversion Rating",
y="Preference Rating")
extravert_facet
# boxplot AND jitter plot, x axis is age and y is quietness preference
freestyle = ggplot(
data=new_data,
aes(y=factor(RestaurantPrefs_quiet),x=Age)
) +
geom_boxplot(fill="#f4c2c2") +
geom_jitter(color="#981b1b", alpha=0.5, size=1.2) +
labs(title="Preference for Quiet Restaurants Based on Age", y="Preference for Quiet Restaurants")
freestyle
library(ggplot)
library(ggplot2)
library(readr)
library(dplyr)
library(sf)
load("PubPol4557Session21.Rdata")
getwd()
library(readxl)
library(dplyr)
ABIII <- read_excel("ABIII_Palestine_subset.xlsx")
library(dplyr)
x == median(c(8,14,3,9,15,5,5,21,6,8))
x <- c(8,14,3,9,15,5,5,21,6,8)
x == median(x)
median(x)
x == median(x) | x!=21
x == median(x) | x>15
for (i in 1:4 * 5) {
for (j in 1:15) {
print(x+=1)
x <- 0
for (i in 1:4 * 5) {
for (j in 1:15) {
x = x+1
}
}
#install.packages('kernlab')
install.packages('kknn')
library(kknn)
library(kknn)
#install.packages('smooth')
library(smooth)
library(tidyr)
library(ggplot2)
library(lubridate)
library(dplyr)
temp_df <- read.table('temps.txt', header = TRUE)
exp(0.03*50000)
?exp
exp(0.03*50000)*2+10
exp(0.2)
log(exp(0.03*50000))
knitr::opts_chunk$set(echo = TRUE)
#install.packages("imager")
#install.packages("OpenImageR")
#install.packages("BiocManager")
#BiocManager::install("EBImage")
library(EBImage)
library(OpenImageR)
library(imager)
setwd("~/Desktop/Summer 2025/HW2")
rm(list=ls())
#Part d
dev.off()
#Part d
histogram <- hist(grayscaled, breaks=256, xlab='colour scale',main='')
knitr::opts_chunk$set(echo = TRUE)
#install.packages("imager")
#install.packages("OpenImageR")
#install.packages("BiocManager")
#BiocManager::install("EBImage")
library(EBImage)
library(OpenImageR)
library(imager)
setwd("~/Desktop/Summer 2025/HW2")
rm(list=ls())
#Part a
path = 'images/horse1-5.jpg'
horse = load.image(path)
plot(horse)
#Part b
original <- readImage(path)
dim(original)
new_width <- dim(original)[1] / 3
resized <- EBImage::resize(original, w=new_width)
dim(resized)
#Part c
grayscaled <- grayscale(horse)
plot(grayscaled)
bwhorse <- grayscaled
bwhorse[grayscaled < 0.5] = 0
bwhorse[grayscaled >= 0.5] = 1
plot(bwhorse)
#Part d
histogram <- hist(grayscaled, breaks=256, xlab='colour scale',main='')
#Part e
lin_horse2 <- 254 - grayscaled
log_horse_1 <- 20*log(grayscaled+1)
log_horse_2 <- 40*log(grayscaled+1)
plot(log_horse_1)
plot(log_horse_2)
shifted_horse <- grayscaled*256
stretch_horse <- (shifted_horse - min(shifted_horse)) / max(shifted_horse)
#Part f
imnoise(mean=0, sd = 10)
#Part f
imnoise(100, 563,mean=0, sd = 10)
#Part f
imnoise(1000, 563,mean=0, sd = 10)
#Part f
grayscaled + imnoise(1000, 563,mean=0, sd = 10)
#Part f
noisy_image <- grayscaled + imnoise(1000, 563,mean=0, sd = 10)
plot(noisy_image)
clean_mat <- matrix(data = 1, nrow = 3, ncol = 3)
1/9*clean_mat*noisy_image
width = dim(grayscaled)[1]
height = dim(grayscaled)[2]
clean_mat <- matrix(data = 1, nrow = 3, ncol = 3)
padded_image = matrix(data = 0, nrow = width+2, ncol=height+2)
image <- as.matrix(grayscaled)
padded_image[1:width,1:height] <- image
clean_image <- matrix(data = 0, nrow = width, ncol=height)
for (i in 1:width){
for (k in 1:height){
i_end = i+2
k_end = k+2
temp <-padded_image[i:i_end,k:k_end]
clean_image[i,k] <- sum(temp * 1/9 * clean_mat)
}
}
plot(as.cimg(clean_image))
sharp_mask <- matrix(c(-1,-1,-1,-1,9,-1,-1,-1,-1), nrow=3, ncol=3, byrow = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(imager)
library(OpenImageR)
setwd("~/Desktop/Summer 2025/HW2")
rm(list=ls())
D1 <- edge_detection(image, method = 'LoG', sigma = 0.8, gaussian_dims = 5)
knitr::opts_chunk$set(echo = TRUE)
library(imager)
library(OpenImageR)
setwd("~/Desktop/Summer 2025/HW2")
rm(list=ls())
eagle <- load.image('images/Eagle-3.jpg')
gray_eagle <- grayscale(eagle)
width = dim(gray_eagle)[1]
height = dim(gray_eagle)[2]
kernel = 3
plot(gray_eagle)
Mx = matrix(c(-1,0,1,-2,0,2,-1,0,1), nrow = 3, ncol=3, byrow=TRUE)
My = matrix(c(-1,-2,-1,0,0,0,1,2,1), nrow = 3, ncol=3, byrow=TRUE)
padded_image = matrix(data = 0, nrow = width+2, ncol=height+2)
image <- as.matrix(gray_eagle)
padded_image[1:width,1:height] <- image
x_image <- matrix(data = 0, nrow = width, ncol=height)
y_image <-  matrix(data = 0, nrow = width, ncol=height)
for (i in 1:width){
for (k in 1:height){
i_end = i+2
k_end = k+2
temp <-padded_image[i:i_end,k:k_end]
x_grad <- sum(temp * Mx)
y_grad <- sum(temp*My)
x_image[i,k] <- x_grad
y_image[i,k] <- y_grad
}
}
f_image = (x_image*x_image)+(y_image*y_image)
f_image_c <- as.cimg(f_image)
plot(f_image_c)
log_image <- edge_detection(image, method = 'LoG', sigma = 1, gaussian_dims = 5)
plot(as.cimg(log_image))
D1 <- edge_detection(image, method = 'LoG', sigma = 0.8, gaussian_dims = 5)
D2 <- edge_detection(image, method = 'LoG', sigma = 0.8*1.6, gaussian_dims = 5)*0.98
DoG - D1 - D2
DoG <- D1 - D2
new_mat <- matrix(0, nrows=r, ncol=c)
new_mat <- matrix(data=0, nrows=r, ncol=c)
new_mat <- matrix(data=0, nrows=r, ncol=c)
new_mat <- matrix(data=0, nrow=r, ncol=c)
r <- dim(DoG)[1]
c <- dim(DoG)[2]
new_mat <- matrix(data=0, nrow=r, ncol=c)
for (rows in 1:r){
for (cols in 1:c){
if (DoG[i,k] >= -0.1){
new_mat[i,k] = 1
} else if (DoG[i,k]<-0.1){1+tanh(200*(DoG[i,k]+0.1))}
}
}
new_mat
max(new_mat)
new_mat <- ifelse(DoG >= -0.1,
1,
1 + tanh(200 * (DoG + 0.1)))
plot(as.cimg(new_mat))
knitr::opts_chunk$set(echo = TRUE)
#library(EBImage)
#library(OpenImageR)
library(imager)
setwd("~/Desktop/Summer 2025/HW2")
rm(list=ls())
I = load.image('images/Q2part1-1.jpg')
Ix <- imgradient(I, axes='x', scheme = 1)
Iy <- imgradient(I, axes='y')
plot(I)
plot(Ix)
plot(Iy)
Ix**2
df <- c(Ix**2,Ix*Iy,Ix*Iy,Iy**2)
H <- matrix(df,nrow = 2, ncol=2, byrow = TRUE)
rm(df)
df <- [[1,1],[0,0]]
df <- c([1,1],[0,0])
df <- c(c(1,1),c(0,0))
df
df <- df(c(1,1),c(0,0))
df
df <- as.data.frame(c(1,1),c(0,0))
?df
grad_mat <- matrix(list(Ix**2, Ix*Iy, Ix*Iy, Iy**2))
grad_mat <- matrix(list(Ix**2, Ix*Iy, Ix*Iy, Iy**2),2)
grad_mat
2*grad_mat
Ix <- as.matrix(Ix)
Iy <- as.matrix(Iy)
grad_mat <- matrix(list(Ix**2, Ix*Iy, Ix*Iy, Iy**2),2)
2*grad_mat
View(grad_mat)
clear
exit
# Omar Masood
# Task 3: Variable Creation
library(dplyr)
library(tidyr)
load("PubPol477477Task3F22.Rdata")
library(dplyr)
library(tidyr)
load("PubPol577Task3.R")
setwd("~/Desktop/Projects/RProjects/DataWrangling")
library(dplyr)
library(tidyr)
load("PubPol577Task3.R")
library(dplyr)
library(tidyr)
load("PubPol477477Task3F22.Rdata")
library(dplyr)
library(tidyr)
load("fueldata.Rdata")
dim(AIRBAGS)
names(AIRBAGS)
str(AIRBAGS)
AIRBAGS$carage <- AIRBAGS$yearacc - AIRBAGS$yearVeh
AIRBAGS <- AIRBAGS %>% mutate(
seatbeltmand = case_when(yearVeh <= 1973 ~ 0,
yearVeh > 1973 ~ 1),
airbagmand = case_when(yearVeh <= 1988 ~ 0,
yearVeh > 1988 ~ 1)
)
AIRBAGS <- separate(AIRBAGS, col=caseid, into=c("sample", "case","vehicleNum"),sep=":")
library(dplyr)
library(tidyr)
load("prisondata.Rdata")
MISCHOOL <- full_join(x=MIENROLL,y=MITEACHERS,by='DistrictCode',copy=FALSE)
MISCHLALL <- full_join(x=MISCHOOL,y=MIDEMO, by = c('CtyCode.x'='CountyCode'))
#Question 3
PRISONWIDER <- PRISONLONG %>% pivot_wider(names_from = legal,
values_from = count)
PRISONGATHER <- gather(data = PRISONWIDE,key="legal",value='value',2:33)
PRISONSEPARATE <- separate(data=PRISONGATHER,
col=legal,
into=c('state','gender','legal'),
sep=c(3,4))
PRISONLONGER <- PRISONSEPARATE %>% pivot_wider(names_from = legal,values_from = legal)
#Question 4
table(DANVILLE$owncell)
table(DANVILLE$haveline)
table(DANVILLE$danville)
table(DANVILLE$neighbor,DANVILLE$danville <= 3, useNA = "ifany")
##Omar Masood | PubPol 577 | Task 5
library(dplyr)
library(haven)
library(estimatr)
load("oecd.RData")
##Omar Masood | PubPol 577 | Task 5
library(dplyr)
library(haven)
library(estimatr)
load("oecd.RData")
#Q1a
cor(OECD$longir,OECD$unemp, use="complete.obs")
cor(OECD$longir,OECD$gdpdef, use="complete.obs")
cor(OECD$curacct,OECD$labprod, use="complete.obs")
#Q2b
cor(subset(OECD,select=-c(cty)))
#Q3
SUBSET2003 <- subset(OECD, year == 2003)
SUBSET2009 <- subset(OECD, year == 2009)
SUBSET2016 <- subset(OECD, year == 2016)
t.test(SUBSET2003$unemp, SUBSET2009$unemp)
t.test(SUBSET2009$unemp, SUBSET2016$unemp)
#Q4
chisq.test(DANVILLE$daysafe,DANVILLE$nitesafe)
chisq.test(DANVILLE$danville,DANVILLE$nitesafe)
chisq.test(DANVILLE$owncell,DANVILLE$haveline)
#Q8a
vote <- glm(signed ~ b_per_farm + b_GPP + b_GAGG + b_PAG + b_col +
b_percap + b_unemp + b_nen + DPJ + new + SMD + b_farmxSMD,
data = DIET, family = binomial)
#Q7
DIET <- read_dta("TPPedit.dta")
DIET <- read_dta("TPPedit.dta")
summary(DIET)
#Q8a
vote <- glm(signed ~ b_per_farm + b_GPP + b_GAGG + b_PAG + b_col +
b_percap + b_unemp + b_nen + DPJ + new + SMD + b_farmxSMD,
data = DIET, family = binomial)
summary(vote)
#Q8b
voteprbt <- glm(signed ~ b_per_farm + b_GPP + b_GAGG + b_PAG + b_col +
b_percap + b_unemp + b_nen + DPJ + new + SMD + b_farmxSMD,
data = DIET, family = binomial(link = probit))
summary(voteprbt)
#Q8c
votelm <- lm_robust(signed ~ b_per_farm + b_GPP + b_GAGG + b_PAG + b_col +
b_percap + b_unemp + b_nen + DPJ + new + SMD + b_farmxSMD,
data = DIET)
summary(votelm)
plot(vote)
library(ggplot2)
plot(vote)
vote$y
plot(ggpredict(vote,"Voting"))
##Omar Masood | PubPol 577 | Task 5
install.packages(ggeffects)
##Omar Masood | PubPol 577 | Task 5
install.packages("ggeffects")
library(ggeffects)
vote <- glm(signed ~ b_per_farm + b_GPP + b_GAGG + b_PAG + b_col +
b_percap + b_unemp + b_nen + DPJ + new + SMD + b_farmxSMD,
data = DIET, family = binomial)
summary(vote)
plot(ggpredict(vote,"Voting"))
ggpredict(vote,"Voting")
ggpredict(vote)
plot(ggpredict(vote))
View(DIET)
plot(ggpredict(vote,c("b_per_farm", "b_GPP", "b_GAGG", "b_PAG", "b_col",
"b_percap","b_unemp","b_nen","DPJ", "new","SMD","b_farmxSMD")))
plot(ggpredict(votelm,c("b_per_farm", "b_GPP", "b_GAGG", "b_PAG", "b_col",
"b_percap","b_unemp","b_nen","DPJ", "new","SMD","b_farmxSMD")))
table(is.na(DANVILLE$owncell), is.na(DANVILLE$haveline))
#Q5
ELECTRIC <- read_dta("ReplicationDataedit.dta")
summary(ELECTRIC)
